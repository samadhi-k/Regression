# -*- coding: utf-8 -*-
"""regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BwcgGouDN-o6gwW04rrHOSRUT9CW1gky
"""



from google.colab import drive
drive.mount('/content/drive')

"""### Import Packages"""

import numpy as np;
import pandas as pd;
import matplotlib.pyplot as plt;

"""### Import Datasets"""

train = pd.read_csv('/content/drive/MyDrive/DataSets/Lab2Regression/train.csv')
test = pd.read_csv('/content/drive/MyDrive/DataSets/Lab2Regression/test.csv')

train.describe()

"""according to above there are no missing values."""

features = train.columns[1:-1]
X_train = train[features]
Y_train = train['cost']
X_test = test[features]

"""### Check varience of the features"""

#feature varience plot
plt.figure(figsize=(20,10))
plt.scatter(X_train.columns, X_train.var())

"""since most of the feature varience is ~0 no features removed

### Correlation check
"""

import seaborn as sns;

plt.figure(figsize=(20,10))
dataplot = sns.heatmap(X_train.corr(), cmap="YlGnBu", annot=True)
plt.show()

def correlation(dataset, threshold):
    col_corr = set()  # Set of all the names of correlated columns
    corr_matrix = dataset.corr()
    for i in range(len(corr_matrix.columns)):
        for j in range(i):
            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value
                colname = corr_matrix.columns[i]  # getting the name of column
                col_corr.add(colname)
    return col_corr

corr_features = correlation(X_train, 0.9)
len(set(corr_features))

X_train = X_train.drop(corr_features, axis = 1)
X_test = X_test.drop(corr_features, axis = 1)

final_columns = X_train.columns

from sklearn.preprocessing import RobustScaler;

transformer = RobustScaler().fit(X_train)
X_train = transformer.transform(X_train)

X_test_scaled = transformer.transform(X_test)

X_train = pd.DataFrame(X_train, columns = final_columns)

X_train.describe()

from sklearn.model_selection import train_test_split;

#split the dataset
X_train_final,  X_valid,Y_train_final, Y_valid = train_test_split(X_train, Y_train, test_size = 0.2, random_state = 0)

"""### XGBoost Regressor"""

import xgboost as xgb

X_train_final.shape, Y_train_final.shape, X_valid.shape, Y_valid.shape

dtrain = xgb.DMatrix(X_train_final, label=Y_train_final)
dvalid = xgb.DMatrix(X_valid, label=Y_valid)

from sklearn.metrics import mean_squared_error;
from sklearn.model_selection import GridSearchCV

param_grid = {
    'max_depth': [3, 4, 5],
    'learning_rate': [0.01, 0.05, 0.1],
    'n_estimators': [50, 100, 200],
}

model = xgb.XGBRegressor(objective='reg:squarederror', tree_method='hist', device='cuda')
grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_root_mean_squared_error', cv=3, n_jobs=-1)
grid_search.fit(X_train_final, Y_train_final)
best_params = grid_search.best_params_
best_model = xgb.XGBRegressor(
    objective='reg:squarederror',
    tree_method='hist',
    device='cuda',
    **best_params
)
best_model.fit(X_train_final, Y_train_final)

# Make predictions on the test data
y_pred = best_model.predict(X_valid)

# Evaluate the model's performance
rmse = mean_squared_error(Y_valid, y_pred, squared=False)

print(f"Best Hyperparameters: {best_params}")
print(f"Root Mean Squared Error: {rmse}")

y_xgb_test = best_model.predict(X_test_scaled)

y_xgb_test = best_model.predict(X_test_scaled)

result = pd.DataFrame({'id':test['id'], 'cost':y_xgb_test})
result.to_csv('XGboost.csv', index=False)

"""### Catboost Regressor"""

!pip install catboost

from catboost import CatBoostRegressor, cv

# Define the hyperparameters grid for grid search
param_grid = {
    'learning_rate': [0.01],
    'depth': [6, 8, 10, 15],
    'iterations': [100, 200, 300]
}

# Create the CatBoost regressor
catboost_reg = CatBoostRegressor(task_type="GPU", devices='0:1')  # Specify GPU device(s)

# Perform Grid Search
grid_search = GridSearchCV(estimator=catboost_reg, param_grid=param_grid, cv=3, scoring='neg_root_mean_squared_error', verbose=2)
grid_search.fit(X_train_final, Y_train_final)

# Get the best parameters from the grid search
best_params = grid_search.best_params_
print(f'Best Parameters: {best_params}')

# Train the model with the best parameters
best_catboost_reg = CatBoostRegressor(task_type="GPU", devices='0:1', **best_params)
best_catboost_reg.fit(X_train_final, Y_train_final)

# Make predictions
y_pred_cat = best_catboost_reg.predict(X_valid)

# Calculate and print the RMSE (Root Mean Squared Error)
rmse = mean_squared_error(Y_valid, y_pred_cat, squared=False)
print(f'RMSE: {rmse:.2f}')

print(f'Best Parameters: {best_params}')
print(f'RMSE: {rmse:.2f}')

y_cat_test = best_catboost_reg.predict(X_test_scaled)

result = pd.DataFrame({'id':test['id'], 'cost':y_cat_test})
result.to_csv('catBoost.csv', index=False)

"""###  Voting regressor"""

from sklearn.ensemble import VotingRegressor

# cat regressor and XGBoost regressor
models = [('cat', best_catboost_reg), ('xgb', best_model)]

# Create a Voting Regressor
voting_regressor = VotingRegressor(estimators=models)

# Fit the Voting Regressor on your data
voting_regressor.fit(X_train_final, Y_train_final)

# Predict using the Voting Regressor
y_pred_voting = voting_regressor.predict(X_valid)

# Evaluate the performance
rmse = mean_squared_error(Y_valid, y_pred_voting, squared=False)
print(f'Root Mean Squared Error: {rmse}')

print(f'RMSE: {rmse:.2f}')

y_voting_test = voting_regressor.predict(X_test_scaled)

result = pd.DataFrame({'id':test['id'], 'cost':y_voting_test})
result.to_csv('voting.csv', index=False)

"""### Stacking"""

from sklearn.ensemble import StackingRegressor

# cat regressor and XGBoost regressor
models = [('cat', best_catboost_reg), ('xgb', best_model)]

# Create the Stacking Regressor
stacking_regressor = StackingRegressor(
    estimators=models,
    final_estimator=best_catboost_reg
)

# Fit the Stacking Regressor on your data
stacking_regressor.fit(X_train_final, Y_train_final)

# Predict using the Stacking Regressor
y_pred_stacking = stacking_regressor.predict(X_valid)

# Evaluate the performance
rmse = mean_squared_error(Y_valid, y_pred_stacking, squared=False)
print(f'Mean Squared Error: {rmse}')

print(f'RMSE: {rmse:.2f}')

y_stacking_test = stacking_regressor.predict(X_test_scaled)

result = pd.DataFrame({'id':test['id'], 'cost':y_stacking_test})
result.to_csv('stacking.csv', index=False)